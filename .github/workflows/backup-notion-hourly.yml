name: Notion API Backup (Direct Request Mode)

permissions:
  contents: write

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install requests pandas

      - name: Backup Notion Data
        env:
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
        run: |
          python - <<'EOF'
          import os
          import requests
          import pandas as pd
          from pathlib import Path

          # Setup
          NOTION_TOKEN = os.environ["NOTION_TOKEN"]
          HEADERS = {
              "Authorization": f"Bearer {NOTION_TOKEN}",
              "Content-Type": "application/json",
              "Notion-Version": "2022-06-28"
          }
          output_dir = Path("notion-backup")
          output_dir.mkdir(exist_ok=True)

          ROOT_IDS = [
              "2fe86657637a80709d98e8848581f4c7", # CRM Hub
              "2fe86657637a80cc8410f9e45f444435",  # Goals Tracker
              "26ef71dcda404662b9c4e34698547e91", # Tasks
              "4df80654477e4070875b7298c76b5487"  # checking a doc that contain only text if it can be pushed
          ]

          def extract_properties(row):
              props = row.get("properties", {})
              row_data = {"Page ID": row["id"], "URL": row.get("url")}
              for name, content in props.items():
                  p_type = content.get("type")
                  val = content.get(p_type)
                  if p_type in ["title", "rich_text"]:
                      row_data[name] = "".join([t.get("plain_text", "") for t in val]) if val else ""
                  elif p_type == "select" and val:
                      row_data[name] = val.get("name", "")
                  elif p_type == "multi_select" and val:
                      row_data[name] = ", ".join([v.get("name", "") for v in val])
                  elif p_type == "date" and val:
                      row_data[name] = val.get("start", "")
                  elif p_type in ["number", "checkbox", "url", "email"]:
                      row_data[name] = val
                  else:
                      row_data[name] = str(val) if val is not None else ""
              return row_data

          def backup_database(db_id, title):
              print(f"    [OK] Extracting Database: {title}")
              url = f"https://api.notion.com/v1/databases/{db_id}/query"
              all_rows = []
              has_more = True
              next_cursor = None

              while has_more:
                  payload = {"start_cursor": next_cursor} if next_cursor else {}
                  response = requests.post(url, headers=HEADERS, json=payload)
                  if response.status_code != 200:
                      print(f"      -> Error: {response.text}")
                      break
                  
                  data = response.json()
                  all_rows.extend(data.get("results", []))
                  has_more = data.get("has_more", False)
                  next_cursor = data.get("next_cursor")

              if all_rows:
                  df = pd.DataFrame([extract_properties(r) for r in all_rows])
                  safe_title = "".join(c if c.isalnum() or c in " -" else "_" for c in title).strip()
                  df.to_csv(output_dir / f"{safe_title}.csv", index=False)
                  print(f"      -> Saved {len(all_rows)} rows.")

          def scan_block(block_id):
              """Recursive crawl using direct API calls"""
              # 1. Try to treat as database
              db_url = f"https://api.notion.com/v1/databases/{block_id}"
              res = requests.get(db_url, headers=HEADERS)
              if res.status_code == 200:
                  db_data = res.json()
                  title = db_data["title"][0]["plain_text"] if db_data["title"] else "Database"
                  backup_database(block_id, title)
                  return

              # 2. Otherwise, scan children
              child_url = f"https://api.notion.com/v1/blocks/{block_id}/children"
              res = requests.get(child_url, headers=HEADERS)
              if res.status_code == 200:
                  children = res.json().get("results", [])
                  for child in children:
                      if child["type"] == "child_database":
                          backup_database(child["id"], child["child_database"]["title"])
                      elif child.get("has_children"):
                          scan_block(child["id"])

          print("--- Starting Direct API Recursive Backup ---")
          for root_id in ROOT_IDS:
              print(f"Scanning Root: {root_id}")
              scan_block(root_id)
          print("\n--- Backup finished ---")
          EOF

      - name: Commit and push changes
        run: |
          git config user.name "Nihad-BIT"
          git config user.email "nihadNV@proton.me"
          git add notion-backup/
          git diff --staged --quiet || (git commit -m "Auto-backup Notion: $(date '+%Y-%m-%d %H:%M')" && git push)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
